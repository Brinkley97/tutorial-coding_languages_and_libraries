{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Workflow\n",
    "- TUTORIAL: [PyTorch for Deep Learning & Machine Learning â€“ Full Course](https://www.youtube.com/watch?v=V_xro1bcAuA&t=27320s) by Daniel Bourke "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "what_were_covering = {1: \"data (prepare and load)\",\n",
    "    2: \"build model\",\n",
    "    3: \"fitting the model to data (training)\",\n",
    "    4: \"making predictions and evaluating a model (inference)\",\n",
    "    5: \"saving and loading a model\",\n",
    "    6: \"putting it all together\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "torch.__version__\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "sys.path.append(os.path.join(notebook_dir, '../../applied_time_series_and_machine_learning/framework_for_time_series_data/tslearn/'))\n",
    "\n",
    "from ml_models import LinearRegressionModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data (preparing and loading)\n",
    "\n",
    "1. Get data into a numerical representation.\n",
    "2. Build a model to learn patterns in that numerical representations.\n",
    "\n",
    "Linear Regression with known **parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3000],\n",
       "        [0.3140],\n",
       "        [0.3280],\n",
       "        [0.3420],\n",
       "        [0.3560],\n",
       "        [0.3700],\n",
       "        [0.3840],\n",
       "        [0.3980],\n",
       "        [0.4120],\n",
       "        [0.4260],\n",
       "        [0.4400],\n",
       "        [0.4540],\n",
       "        [0.4680],\n",
       "        [0.4820],\n",
       "        [0.4960],\n",
       "        [0.5100],\n",
       "        [0.5240],\n",
       "        [0.5380],\n",
       "        [0.5520],\n",
       "        [0.5660],\n",
       "        [0.5800],\n",
       "        [0.5940],\n",
       "        [0.6080],\n",
       "        [0.6220],\n",
       "        [0.6360],\n",
       "        [0.6500],\n",
       "        [0.6640],\n",
       "        [0.6780],\n",
       "        [0.6920],\n",
       "        [0.7060],\n",
       "        [0.7200],\n",
       "        [0.7340],\n",
       "        [0.7480],\n",
       "        [0.7620],\n",
       "        [0.7760],\n",
       "        [0.7900],\n",
       "        [0.8040],\n",
       "        [0.8180],\n",
       "        [0.8320],\n",
       "        [0.8460],\n",
       "        [0.8600],\n",
       "        [0.8740],\n",
       "        [0.8880],\n",
       "        [0.9020],\n",
       "        [0.9160],\n",
       "        [0.9300],\n",
       "        [0.9440],\n",
       "        [0.9580],\n",
       "        [0.9720],\n",
       "        [0.9860]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create *known* parameters\n",
    "weight = 0.7\n",
    "bias = 0.3\n",
    "\n",
    "# Create data\n",
    "start = 0\n",
    "end = 1\n",
    "step = 0.02\n",
    "squeezed_X = torch.arange(start, end, step)\n",
    "unsqueezed_X = squeezed_X.unsqueeze(dim=1) # add extra dim\n",
    "y = weight * unsqueezed_X + bias\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unsqueezed_X), len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data\n",
    "\n",
    "- **GOAL:** Generalization [to perform well on data it hasn't seen before]\n",
    "    - Training set (ie: course materials)\n",
    "    - Validation set (ie: practice exam)\n",
    "    - Testing set (ie: final exam)\n",
    "\n",
    "- There's a direct mapping of training set : testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.986</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0   0.300\n",
       "1   0.314\n",
       "2   0.328\n",
       "3   0.342\n",
       "4   0.356\n",
       "5   0.370\n",
       "6   0.384\n",
       "7   0.398\n",
       "8   0.412\n",
       "9   0.426\n",
       "10  0.440\n",
       "11  0.454\n",
       "12  0.468\n",
       "13  0.482\n",
       "14  0.496\n",
       "15  0.510\n",
       "16  0.524\n",
       "17  0.538\n",
       "18  0.552\n",
       "19  0.566\n",
       "20  0.580\n",
       "21  0.594\n",
       "22  0.608\n",
       "23  0.622\n",
       "24  0.636\n",
       "25  0.650\n",
       "26  0.664\n",
       "27  0.678\n",
       "28  0.692\n",
       "29  0.706\n",
       "30  0.720\n",
       "31  0.734\n",
       "32  0.748\n",
       "33  0.762\n",
       "34  0.776\n",
       "35  0.790\n",
       "36  0.804\n",
       "37  0.818\n",
       "38  0.832\n",
       "39  0.846\n",
       "40  0.860\n",
       "41  0.874\n",
       "42  0.888\n",
       "43  0.902\n",
       "44  0.916\n",
       "45  0.930\n",
       "46  0.944\n",
       "47  0.958\n",
       "48  0.972\n",
       "49  0.986"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y.numpy())\n",
    "y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split_len = int(0.8 * len(unsqueezed_X))\n",
    "train_split_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0   0.00\n",
       "1   0.02\n",
       "2   0.04\n",
       "3   0.06\n",
       "4   0.08\n",
       "5   0.10\n",
       "6   0.12\n",
       "7   0.14\n",
       "8   0.16\n",
       "9   0.18\n",
       "10  0.20\n",
       "11  0.22\n",
       "12  0.24\n",
       "13  0.26\n",
       "14  0.28\n",
       "15  0.30\n",
       "16  0.32\n",
       "17  0.34\n",
       "18  0.36\n",
       "19  0.38\n",
       "20  0.40\n",
       "21  0.42\n",
       "22  0.44\n",
       "23  0.46\n",
       "24  0.48\n",
       "25  0.50\n",
       "26  0.52\n",
       "27  0.54\n",
       "28  0.56\n",
       "29  0.58\n",
       "30  0.60\n",
       "31  0.62\n",
       "32  0.64\n",
       "33  0.66\n",
       "34  0.68\n",
       "35  0.70\n",
       "36  0.72\n",
       "37  0.74\n",
       "38  0.76\n",
       "39  0.78\n",
       "40  0.80\n",
       "41  0.82\n",
       "42  0.84\n",
       "43  0.86\n",
       "44  0.88\n",
       "45  0.90\n",
       "46  0.92\n",
       "47  0.94\n",
       "48  0.96\n",
       "49  0.98"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_df = pd.DataFrame(unsqueezed_X.numpy())\n",
    "X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df, y_train_df = X_df[:train_split_len], y_df[:train_split_len]\n",
    "len(X_train_df), len(y_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df, y_test_df = X_df[train_split_len:], y_df[train_split_len:]\n",
    "len(X_test_df), len(y_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How might we better visualize out data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data=X_train_df.values, train_labels=y_train_df.values, test_data=X_test_df.values, test_labels=y_test_df.values, predictions=None):\n",
    "    \"\"\"Plots training data, test data, and compares predictions\"\"\"\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
    "\n",
    "    if predictions is not None:\n",
    "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
    "    \n",
    "    plt.legend(prop={\"size\": 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predictions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build model\n",
    "\n",
    "- Using OOP in Python. See Real Python: https://realpython.com/python3-object-oriented-programming/\n",
    "- `Linear Regression Model`\n",
    "    1. Goal is to draw the line that passes as close as possible to the points [1 | P 36]\n",
    "    2. Mathematical representation [2 | P 19]\n",
    "        $$\n",
    "        y(x) = w^T \\cdot x + \\epsilon = \\sum_{j=1}^D w_j \\cdot x_j + \\epsilon\n",
    "        $$\n",
    "        \n",
    "        - $w$, weights\n",
    "        - $\\cdot$, matrix multiplication [3]\n",
    "        - $x$, input vector\n",
    "        - $\\epsilon$, residual error or learnable bias parameter between our linear predictions and the true response\n",
    "- Process:\n",
    "    1. Start with random values for our parameters $w$ and $\\epsilon$\n",
    "    2. Look at training data and adjust random our parameters $w$ and $\\epsilon$ to be what would represent the line, hence goal of the LR Model to draw the best fitting line.\n",
    "        - How? Track the gradients [slope] with keyword `require_grad = True` coming from the `torch.autograd` which provides classes and functions.\n",
    "            1. Gradient Descent (GD)\n",
    "                - [adjusts params to find best combination of params]\n",
    "                - [adjusts the params wrt the loss]\n",
    "                - Want our model to converge [approach 0 as we calculate GD]\n",
    "                - Mathematical representation [2 | P 247]\n",
    "                    $$ \\theta_{k + 1} = \\theta_k - \\eta_kg_k$$\n",
    "                - See [4] for a visualization or google gradient in ML\n",
    "            2. Backpropagation [5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a linear regression model class\n",
    "# class OriginalLinearRegressionModel(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(OriginalLinearRegressionModel, self).__init__()\n",
    "#         # Randomly initializations our learnable model parameters\n",
    "#         self.weights = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "#         self.bias = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float32))\n",
    "\n",
    "#         # Forward method to define the computation in the model\n",
    "#     def forward(self, input_x: torch.Tensor) -> torch.Tensor:\n",
    "#         y = self.weights * input_x + self.bias\n",
    "#         return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the contents of our PyTorch model\n",
    "\n",
    "- Use `.parameters()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1166672f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create random seed because we initialize randomly and want to stablize our random values\n",
    "# stablize as in keep random #s same; remove manual_seed() and model params will change\n",
    "# helps with reproducing works\n",
    "stabilizer = 42\n",
    "torch.manual_seed(stabilizer)\n",
    "\n",
    "# original_linear_regression_model = OriginalLinearRegressionModel()\n",
    "\n",
    "# Check out parameters\n",
    "# original_linear_regression_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weights', tensor([0.3367])), ('bias', tensor([0.1288]))])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create instance of model (this is a subclass of of nn.Module)\n",
    "linear_regression_model = LinearRegressionModel(stabilizer)\n",
    "# Check out parameters\n",
    "linear_regression_model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Want `self.weights` and `self.bias` to be close to the ideal `weights` and `bias` set above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Parameter containing:\n",
       " tensor([0.3367], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.1288], requires_grad=True),\n",
       " 0.7,\n",
       " 0.3)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original_linear_regression_model.weights, original_linear_regression_model.bias, linear_regression_model.weights, linear_regression_model.bias, weight, bias\n",
    "linear_regression_model.weights, linear_regression_model.bias, weight, bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions usings `torch.inference_mode()`\n",
    "\n",
    "- See how well model predicts `y_test` based on `X_test`\n",
    "- Pass data through model via `forward()` method\n",
    "- `torch.inference_mode()` \n",
    "    - Removes gradient tracking\n",
    "    - When doing inference, we're NOT training, so don't need to keep track of gradients/ how to update model\n",
    "    - Benefit is that it makes code run faster as we're NOT saving gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make predictions with model\n",
    "# with torch.inference_mode():\n",
    "#     lr_y_preds = linear_regression_model.forward(X_test)\n",
    "\n",
    "# # Similar as above, however inference_mode is preferred\n",
    "# # with torch.no_grad():\n",
    "# #     lr_y_preds = linear_regression_model.forward(X_test)\n",
    "\n",
    "# lr_y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predictions(predictions=lr_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train model\n",
    "\n",
    "- Move from unknown params to known params or from a poor representation of data to better representation\n",
    "    - How?\n",
    "        1. **Loss function:** Calculates how poor or how wrong our model's output vs the true output\n",
    "        2. **Optimizer:** Takes into account the loss of a model and adjusts the model's parameters ($w$, $\\epsilon$) accordingly to improve the loss function\n",
    "        3. **Training loop:**\n",
    "        4. **Testing loop:**\n",
    "\n",
    "- Loss function is also called **criterion** and **cost function**\n",
    "    - Another way other than `nn.L1Loss()` is `torch.mean(torch.abs(y_pred, y_test))`\n",
    "- Learning rate is `lr` [how quickly to adjust the model's parameters\n",
    "    - A hyperparameter [something we set]\n",
    "    - Small `lr` $\\rightarrow$ small params change\n",
    "    - Large `lr` $\\rightarrow$ large params change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a loss function - How wrong out model is\n",
    "loss_fn = nn.L1Loss()\n",
    "\n",
    "# Setup the SGD optimizer\n",
    "# Stochastic [random] gradient descent [adjusts parameters]\n",
    "# Communicates with the loss function by saying\n",
    "# when I randomly adjust these parameters, do we tend in the direction we want?\n",
    "# if so, keep adjusting in this direction and \n",
    "# if no, adjust in the other/another direction\n",
    "optimizer = torch.optim.SGD(params=linear_regression_model.parameters(), lr=0.01) \n",
    "\n",
    "config = [loss_fn, optimizer]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a training and testing loop in PyTorch\n",
    "\n",
    "- Requirements:\n",
    "    1. Loop through the data\n",
    "        1. Forward pass with `forward()` function to make predictions on training data\n",
    "        2. Calculate the loss to compare predictions against truel labels\n",
    "        3. Optimizer zero grad\n",
    "        4. Backpropagation pass to go backwards over the model so we can\n",
    "            1. Calculate the gradients of each param wrt the loss\n",
    "            2. Optimize by adjusting the model's params to improve the loss\n",
    "- Remember with [6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.3367]), tensor([0.1288]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_regression_model.weights.data, linear_regression_model.bias.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #times to loop through the training\n",
    "# # Hyperparameter\n",
    "# epochs = 200\n",
    "\n",
    "# # Track different setups (ie: lr, etc) to compare this experiment to future experiments\n",
    "# epoch_count = []\n",
    "# train_loss_values = []\n",
    "# test_loss_values = []\n",
    "\n",
    "# ### Training\n",
    "# # 0. Loop through the training\n",
    "# for epoch in range(epochs):\n",
    "#     # Set model to training model which \n",
    "#     # sets all parameters that require gradients to require gradients\n",
    "#     linear_regression_model.train()\n",
    "\n",
    "#     # 1. Foward pass\n",
    "#     lr_train_y_preds = linear_regression_model.forward(X_train)\n",
    "\n",
    "#     # 2. Calculate train loss\n",
    "#     train_loss = loss_fn(lr_train_y_preds, y_train)\n",
    "\n",
    "#     # 3. Optimizer zero grad to erase or to zero out gradiens to between 0 - 1\n",
    "#     # Get a fresh start every epoch instead of \n",
    "#     # increasing every time\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     # 4. Backward pass on loss wrt params\n",
    "#     train_loss.backward()\n",
    "\n",
    "#     # 5. Step the optimizer (perform gradient descent)\n",
    "#     # update parameters to get them closer to ideal parameters\n",
    "#     optimizer.step()\n",
    "\n",
    "#     ### Testing\n",
    "#     # turns off gradient tracking to make code faster as we're NOT saving gradients\n",
    "#     linear_regression_model.eval()\n",
    "#     # Predictions\n",
    "#     with torch.inference_mode():\n",
    "\n",
    "#         # 1. Foward pass\n",
    "#         lr_test_y_preds = linear_regression_model.forward(X_test)\n",
    "\n",
    "#         # 2. Calculate test loss\n",
    "#         test_loss = loss_fn(lr_test_y_preds, y_test)\n",
    "\n",
    "#     if epoch % 10 == 0:\n",
    "#         epoch_count.append(epoch)\n",
    "#         print(f\"Epoch: {epoch} | Train loss: {train_loss} | Test loss: {test_loss}\")\n",
    "#         print(f\"Parameters: {linear_regression_model.state_dict()}\")\n",
    "#         train_loss_values.append(train_loss)\n",
    "#         test_loss_values.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loss_values, test_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Train loss: 0.31288138031959534 | Test loss: 0.48106518387794495\n",
      "Parameters: OrderedDict([('weights', tensor([0.3406])), ('bias', tensor([0.1388]))])\n",
      "Epoch: 10 | Train loss: 0.1976713240146637 | Test loss: 0.3463551998138428\n",
      "Parameters: OrderedDict([('weights', tensor([0.3796])), ('bias', tensor([0.2388]))])\n",
      "Epoch: 20 | Train loss: 0.08908725529909134 | Test loss: 0.21729660034179688\n",
      "Parameters: OrderedDict([('weights', tensor([0.4184])), ('bias', tensor([0.3333]))])\n",
      "Epoch: 30 | Train loss: 0.053148526698350906 | Test loss: 0.14464017748832703\n",
      "Parameters: OrderedDict([('weights', tensor([0.4512])), ('bias', tensor([0.3768]))])\n",
      "Epoch: 40 | Train loss: 0.04543796554207802 | Test loss: 0.11360953003168106\n",
      "Parameters: OrderedDict([('weights', tensor([0.4748])), ('bias', tensor([0.3868]))])\n",
      "Epoch: 50 | Train loss: 0.04167863354086876 | Test loss: 0.09919948130846024\n",
      "Parameters: OrderedDict([('weights', tensor([0.4938])), ('bias', tensor([0.3843]))])\n",
      "Epoch: 60 | Train loss: 0.03818932920694351 | Test loss: 0.08886633068323135\n",
      "Parameters: OrderedDict([('weights', tensor([0.5116])), ('bias', tensor([0.3788]))])\n",
      "Epoch: 70 | Train loss: 0.03476089984178543 | Test loss: 0.0805937647819519\n",
      "Parameters: OrderedDict([('weights', tensor([0.5288])), ('bias', tensor([0.3718]))])\n",
      "Epoch: 80 | Train loss: 0.03132382780313492 | Test loss: 0.07232122868299484\n",
      "Parameters: OrderedDict([('weights', tensor([0.5459])), ('bias', tensor([0.3648]))])\n",
      "Epoch: 90 | Train loss: 0.02788739837706089 | Test loss: 0.06473556160926819\n",
      "Parameters: OrderedDict([('weights', tensor([0.5629])), ('bias', tensor([0.3573]))])\n",
      "Epoch: 100 | Train loss: 0.024458957836031914 | Test loss: 0.05646304413676262\n",
      "Parameters: OrderedDict([('weights', tensor([0.5800])), ('bias', tensor([0.3503]))])\n",
      "Epoch: 110 | Train loss: 0.021020207554101944 | Test loss: 0.04819049686193466\n",
      "Parameters: OrderedDict([('weights', tensor([0.5972])), ('bias', tensor([0.3433]))])\n",
      "Epoch: 120 | Train loss: 0.01758546568453312 | Test loss: 0.04060482233762741\n",
      "Parameters: OrderedDict([('weights', tensor([0.6141])), ('bias', tensor([0.3358]))])\n",
      "Epoch: 130 | Train loss: 0.014155393466353416 | Test loss: 0.03233227878808975\n",
      "Parameters: OrderedDict([('weights', tensor([0.6313])), ('bias', tensor([0.3288]))])\n",
      "Epoch: 140 | Train loss: 0.010716589167714119 | Test loss: 0.024059748277068138\n",
      "Parameters: OrderedDict([('weights', tensor([0.6485])), ('bias', tensor([0.3218]))])\n",
      "Epoch: 150 | Train loss: 0.0072835334576666355 | Test loss: 0.016474086791276932\n",
      "Parameters: OrderedDict([('weights', tensor([0.6654])), ('bias', tensor([0.3143]))])\n",
      "Epoch: 160 | Train loss: 0.0038517764769494534 | Test loss: 0.008201557211577892\n",
      "Parameters: OrderedDict([('weights', tensor([0.6826])), ('bias', tensor([0.3073]))])\n",
      "Epoch: 170 | Train loss: 0.008932482451200485 | Test loss: 0.005023092031478882\n",
      "Parameters: OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 180 | Train loss: 0.008932482451200485 | Test loss: 0.005023092031478882\n",
      "Parameters: OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n",
      "Epoch: 190 | Train loss: 0.008932482451200485 | Test loss: 0.005023092031478882\n",
      "Parameters: OrderedDict([('weights', tensor([0.6951])), ('bias', tensor([0.2993]))])\n"
     ]
    }
   ],
   "source": [
    "# #times to loop through the training\n",
    "# Hyperparameter\n",
    "epochs = 200\n",
    "\n",
    "# Track different setups (ie: lr, etc) to compare this experiment to future experiments\n",
    "epoch_count = []\n",
    "train_pred_values = []\n",
    "test_pred_values = []\n",
    "train_loss_values = []\n",
    "test_loss_values = []\n",
    "\n",
    "### Training\n",
    "# 0. Loop through the training\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    train_y_preds, train_loss = linear_regression_model.train_model(X_train_df, y_train_df, config)\n",
    "    test_y_preds, test_loss = linear_regression_model.interpolate_predictions(X_test_df, y_test_df, config)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        epoch_count.append(epoch)\n",
    "        print(f\"Epoch: {epoch} | Train loss: {train_loss} | Test loss: {test_loss}\")\n",
    "        print(f\"Parameters: {linear_regression_model.state_dict()}\")\n",
    "        train_loss_values.append(train_loss)\n",
    "        test_loss_values.append(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss curves\n",
    "plt.plot(epoch_count, np.array(torch.tensor(train_loss_values).numpy()), label=\"Train loss\")\n",
    "plt.plot(epoch_count, test_loss_values, label=\"Test loss\")\n",
    "plt.title(\"Train & Test Loss Curves\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predictions(predictions=train_y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_predictions(predictions=test_y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tkinter.filedialog import askopenfilenames, askdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = askdirectory() + \"/\"\n",
    "MODEL_NAME = \"lr_model.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH + MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "# torch.save(obj=linear_regression_model.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = askopenfilenames(title=\"Select Files\")\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = files[0]\n",
    "MODEL_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new instance of model\n",
    "loaded_linear_regression_model = LinearRegressionModel()\n",
    "loaded_linear_regression_model, loaded_linear_regression_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = torch.load(f=MODEL_FILE)\n",
    "load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_linear_regression_model.load_state_dict(load_model)\n",
    "loaded_linear_regression_model, loaded_linear_regression_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some predictions with loaded model\n",
    "loaded_linear_regression_model.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_model_preds = loaded_linear_regression_model.forward(X_test)\n",
    "loaded_model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_regression_model.eval()\n",
    "with torch.inference_mode():\n",
    "    model_preds = linear_regression_model.forward(X_test)\n",
    "model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_preds == loaded_model_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "1. BOOK: Grokking ML by Luis G. Serrano\n",
    "2. BOOK: Machine Learning a Probabilistic Perpective by Kevin Murphy\n",
    "3. CODE: [Matrix Arithmetic](https://github.com/Brinkley97/lin_alg_for_ml_jason_brownlee/tree/main/part_iv_matrices/9-matricies_matrix_arithmetic) by Detravious Jamari Brinkley\n",
    "4. VIDEO: [Gradient descent, how neural networks learn | Chapter 2, Deep learning](https://www.youtube.com/watch?v=IHZwWFHWa-w&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=3) by 3Blue1Brown\n",
    "5. VIDEO: [What is backpropagation really doing? | Chapter 3, Deep learning](https://www.youtube.com/watch?v=Ilg3gGewQ5U&list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi&index=3) by 3Blue1Brown\n",
    "6. VIDEO: [The Unofficial PyTorch Optimization Loop Song](https://www.youtube.com/watch?v=Nutpusq_AFw) by Daniel Bourke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
